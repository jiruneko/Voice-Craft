{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPsSUysbYnK+b0c7oRGzXNE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiruneko/Voice-Craft/blob/main/voicechange.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5Kg0v1Ldjga"
      },
      "outputs": [],
      "source": [
        "!pip install scipy numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "import IPython.display as ipd\n",
        "\n",
        "# テキストを音素シーケンスに変換する関数の簡易版\n",
        "def text_to_sequence(text, cleaners):\n",
        "    symbols = \"abcdefghijklmnopqrstuvwxyz'!,.? \"\n",
        "    symbol_to_id = {s: i for i, s in enumerate(symbols)}\n",
        "    sequence = [symbol_to_id[s] for s in text.lower() if s in symbol_to_id]\n",
        "    return sequence\n",
        "\n",
        "# Tacotron 2 と WaveGlow のモデルをロード\n",
        "tacotron2 = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_tacotron2', pretrained=True)\n",
        "waveglow = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_waveglow', pretrained=True)\n",
        "\n",
        "# GPU用にモデルを配置し、推論モードに設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tacotron2 = tacotron2.to(device).eval()\n",
        "waveglow = waveglow.to(device).eval()\n",
        "\n",
        "# WaveGlowの一部レイヤーにおけるFP32精度の調整（ノイズ軽減用）\n",
        "for k in waveglow.convinv:\n",
        "    k.float()\n",
        "\n",
        "# 音声合成用のテキスト\n",
        "text = \"Hello, this is a voice synthesis test.\"\n",
        "sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
        "sequence = torch.from_numpy(sequence).to(device=device, dtype=torch.int64)\n",
        "\n",
        "# シーケンス長を取得\n",
        "input_lengths = torch.IntTensor([sequence.shape[1]]).to(device)\n",
        "\n",
        "# Tacotron 2 でメルスペクトログラムを生成\n",
        "with torch.no_grad():\n",
        "    mel_outputs, mel_outputs_postnet, alignments = tacotron2.infer(sequence, input_lengths)\n",
        "\n",
        "# mel_outputs_postnet の形状を確認して3次元テンソルに変換\n",
        "print(\"mel_outputs_postnet shape before reshape:\", mel_outputs_postnet.shape)\n",
        "\n",
        "# 1次元テンソルの場合はエラーを表示して処理を中断\n",
        "if mel_outputs_postnet.dim() == 1:\n",
        "    raise ValueError(\"mel_outputs_postnet is 1-dimensional, indicating an issue with Tacotron2 model output.\")\n",
        "\n",
        "# 形状が2次元であれば、バッチ次元を追加\n",
        "if mel_outputs_postnet.dim() == 2:\n",
        "    mel_for_waveglow = mel_outputs_postnet.unsqueeze(0)\n",
        "else:\n",
        "    mel_for_waveglow = mel_outputs_postnet\n",
        "\n",
        "# 最終的な形状を確認して、WaveGlowの期待する形式に整える\n",
        "print(\"mel_for_waveglow shape after unsqueeze (if applied):\", mel_for_waveglow.shape)\n",
        "\n",
        "# 転置して [batch, n_mel_channels, time_steps] に整形\n",
        "mel_for_waveglow = mel_for_waveglow.permute(0, 2, 1)\n",
        "print(\"mel_for_waveglow shape after transpose:\", mel_for_waveglow.shape)\n",
        "\n",
        "# WaveGlow で音声を生成\n",
        "with torch.no_grad():\n",
        "    audio = waveglow.infer(mel_for_waveglow, sigma=0.666)\n",
        "\n",
        "# 音声データを保存して再生\n",
        "audio_np = audio[0].data.cpu().numpy()\n",
        "write(\"output.wav\", 22050, audio_np)\n",
        "ipd.Audio(\"output.wav\")"
      ],
      "metadata": {
        "id": "rSSajHW3drPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テキストを変換\n",
        "text = \"Hello, this is a voice synthesis test.\"\n",
        "sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
        "sequence = torch.from_numpy(sequence).to(dtype=torch.int64)\n",
        "\n",
        "# Tacotron2でメルスペクトログラムを生成\n",
        "with torch.no_grad():\n",
        "    mel_outputs, mel_outputs_postnet, _, alignments = tacotron2.infer(sequence)\n",
        "\n",
        "# WaveGlowで音声を生成\n",
        "with torch.no_grad():\n",
        "    audio = waveglow.infer(mel_outputs_postnet, sigma=0.666)\n",
        "\n",
        "# 音声データを保存して再生\n",
        "audio_np = audio[0].data.cpu().numpy()\n",
        "write(\"output.wav\", 22050, audio_np)\n",
        "ipd.Audio(\"output.wav\")"
      ],
      "metadata": {
        "id": "B4qEsTNdd0qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l4AJhFjWehOS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}